{"nbformat_minor": 1, "cells": [{"source": "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Watson Studio\u3067\u6587\u5b57\u30c7\u30fc\u30bf\u3092\u53ef\u8996\u5316\u3057\u3088\u3046\n\ntwitter\u304b\u3089\u6c17\u306b\u306a\u308b\u60c5\u5831\u3092\u53d6\u5f97\u3057\u3001 Watson Natural Languege Understanding\u3067Keyword\u62bd\u51fa\u3001WorldCloud\u3092PixieDust \u3092\u4f7f\u7528\u3057\u3066\u8868\u793a\u3057\u3066\u307f\u307e\u3057\u3087\u3046!", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"part1\"></a>\n# Part 1 - \u5206\u6790\u30c7\u30fc\u30bf\u4f5c\u6210\n<a id=\"setup\"></a>\n## 1. Setup\n### 1.1 \u6700\u65b0\u306e Watson Developer Cloud, requests-oauthlib \u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u5c0e\u5165\nNatural\u3000Languge\u3000Understanding\u306b\u4f7f\u7528\u3059\u308bWatson Developer Cloud\u3068Twitter\u306eOAuth\u8a8d\u8a3c\u306b\u4f7f\u7528\u3059\u308b requests-oauthlib\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5c0e\u5165\u3057\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "!pip install --upgrade ibm-watson\n\n!pip install requests requests_oauthlib", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"pixie\"></a>\n### 1.2 PixieDust Library\u306e\u5c0e\u5165\n\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001PixieDust\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f7f\u7528\u3057\u3066\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u5206\u6790\u304a\u3088\u3073\u8996\u899a\u5316\u3057\u307e\u3059\u3002\n\nPixieDust\u306e\u8a73\u7d30\u306f[Introductory Notebook](https://dataplatform.cloud.ibm.com/exchange/public/entry/view/5b000ed5abda694232eb5be84c3dd7c1) \u307e\u305f\u306f [PixieDust Github](https://ibm-cds-labs.github.io/pixiedust/)\u3000\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n", "cell_type": "markdown", "metadata": {}}, {"source": "\u6b21\u306e\u30bb\u30eb\u3092\u5b9f\u884c\u3057\u3066\u3001\u6700\u65b0\u30d0\u30fc\u30b8\u30e7\u30f3\u306ePixieDust\u3092\u5b9f\u884c\u3057\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002 \u30ed\u30fc\u30ab\u30eb\u306ejupyter notyebook\u3092\u4f7f\u7528\u3057\u3001PixieDust\u3092\u30ed\u30fc\u30ab\u30eb\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u3067\u3001\u305d\u308c\u3092\u4f7f\u7528\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u30bb\u30eb\u3092\u5b9f\u884c\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002\n\n\u5c1a\u3001\u6b63\u5f0f\u30ea\u30ea\u30fc\u30b9\u524d\u306e`https://github.com/pixiedust/pixiedust.git@va-working-branch#egg=pixiedust`\u306f\u30d5\u30a9\u30f3\u30c8\u6307\u5b9a\u304c\u53ef\u80fd\u306a\u30e2\u30b8\u30e5\u30fc\u30eb\u3067\u3001\u6b63\u5f0f\u30ea\u30ea\u30fc\u30b9\u307e\u3067\u4e00\u6642\u7684\u306b\u5229\u7528\u3057\u3066\u3044\u307e\u3059\u3002\u65e5\u672c\u8a9e\u8868\u793a\u3092\u53ef\u80fd\u306b\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "# To confirm you have the latest version of PixieDust on your system, run this cell\n#!pip install -U --no-deps pixiedust\n!pip install --upgrade --no-deps git+https://github.com/pixiedust/pixiedust.git@va-working-branch#egg=pixiedust", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "PixieDust\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3057\u3001\u30ab\u30fc\u30cd\u30eb\u3092Restart\u304c\u5fc5\u8981\u306a\u5834\u5408\u306fRestart\u3055\u305b\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "import pixiedust", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": " #### 1.4\u3000Option\n <span style=\"color: red\">Pixiedust runtime updated. Please restart kernel</span>  \u3068\u8868\u793a\u3055\u308c\u305f\u5834\u5408\u306f\u3001\u4e0a\u306e\u30e1\u30cb\u30e5\u30fc\u306e`Kernel`-> `Restart`\u304b\u3089\u30ab\u30fc\u30cd\u30eb\u3092Restart\u3055\u305b\u3066\u304f\u3060\u3055\u3044\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"wordcloud\"></a>\n### 1.3 wordcloud Library\u306e\u5c0e\u5165\n\n\u65e5\u672c\u8a9e\u304c\u8868\u793a\u3067\u304d\u308b\u3088\u3046\u306b\u3001\u65e5\u672c\u8a9e\u30d5\u30a9\u30f3\u30c8\u3082\u5c0e\u5165\u3057\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "!pip install --user wordcloud", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#\u65e5\u672c\u8a9e\u30d5\u30a9\u30f3\u30c8\u306e\u5c0e\u5165\njp_font_path ='/home/dsxuser/work/ipaexg00301/ipaexg.ttf'\n\nimport os\nif not os.path.exists(jp_font_path):\n    !wget https://oscdl.ipa.go.jp/IPAexfont/ipaexg00301.zip\n    !unzip ipaexg00301.zip\nelse:\n    print('IPA font ha\uff53 been already installed')\n ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"pixie_wordcloud\"></a>\n### 1.4 PixieDust \u306bWordCloud\u306e\u8a2d\u5b9a\nPixieDust\u306bWordCloud\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u304c\u8868\u793a\u3067\u304d\u308b \u30c1\u30e3\u30fc\u30c8\u3092\u8ffd\u52a0\u3057\u307e\u3057\u3087\u3046\u3002\nPixieDust\u306f\u81ea\u5206\u3067\u8a2d\u5b9a\u3057\u305f\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u30c7\u30fc\u30bf\u8868\u793a\u3059\u308b\u30c1\u30e3\u30fc\u30c8\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\u4eca\u56de\u306f\uff11\u5217\u76ee\u306bwordcloud\u306b\u8868\u793a\u3059\u308b\u6587\u5b57\u3001\uff12\u5217\u76ee\u306b\u305d\u306e\u8868\u793aVolume\u6570\u3092\u5165\u308c\u305fpandas\u306eDataFrame\u3092\u6e21\u3059\u3068\u3001wordcloud\u3092\u8868\u793a\u3059\u308b\u30c1\u30e3\u30fc\u30c8\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\n\u4f8b\u3048\u3070\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u3067\u3059:\n\n```\nimport pandas as pd\ndf = pd.DataFrame([[\"\u56db\u6708\", 26],[\"May\", 10],[\"June\", 5]],  columns=['key', 'value'])\n```\n| \u3000 |  Key  | Value |\n| ---- | ---- | ---- |\n|  0  |  \u56db\u6708  | 26 |\n|  1  |  May  | 10 |\n|  2  |  June  | 5 |", "cell_type": "markdown", "metadata": {}}, {"source": "from pixiedust.display.display import *\nimport io\nimport base64\nfrom wordcloud import WordCloud\n\nclass SimpleWordCloudDisplay(Display):\n    def doRender(self, handlerId):\n        # convert from dataframe to dict\n        dfdict = {}\n       # df = self.entity.toPandas()\n        df = self.entity\n        for x in range(len(df)):\n            currentid = df.iloc[x,0] or 'NoKey'\n            currentvalue = df.iloc[x,1]\n            dfdict.setdefault(currentid, 0)\n            dfdict[currentid] = dfdict[currentid] + currentvalue\n\n        # create word cloud from dict\n        wc = WordCloud(background_color=\"white\",  width=800, height=400, max_font_size=140, font_path=jp_font_path).fit_words(dfdict)\n        #wc = WordCloud(background_color=\"white\", max_font_size=140, font_path=jp_font_path).fit_words(dfdict)\n\n\n        # encode word cloud image to base64 string\n        img = wc.to_image()\n        buffer =io.BytesIO()\n        img.save(buffer,format=\"JPEG\")                  #Enregistre l'image dans le buffer\n        myimage = buffer.getvalue()  \n        img_str = base64.b64encode(myimage)\n      \n\n        self._addHTMLTemplateString(\n\"\"\"\n<center><img src=\"data:image/png;base64,{0}\"></center>\n\"\"\".format(img_str.decode(\"ascii\"))\n            \n        )", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "@PixiedustDisplay()\nclass SimpleWordCloudMeta(DisplayHandlerMeta):\n    @addId\n    def getMenuInfo(self,entity,dataHandler):\n        if entity.__class__.__name__ == \"DataFrame\":\n            return [\n                {\n                    \"categoryId\": \"Chart\",\n                    \"title\": \"Simple Word Cloud\",\n                    \"icon\": \"fa-cloud\",\n                    \"id\": \"mySimpleWordCloud\"\n                }\n            ]\n        else:\n            return []\n\n    def newDisplayHandler(self,options,entity):\n        return SimpleWordCloudDisplay(options,entity)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### 1.5 WordCloud\u306eTest\n\u8868\u793a\u3067\u304d\u308b\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\uff01", "cell_type": "markdown", "metadata": {}}, {"source": "#Test Code\nimport pandas as pd\njp_font_path='/home/dsxuser/work/ipaexg00301/ipaexg.ttf'\ndf = pd.DataFrame([[\"\u56db\u6708\", 26],[\"May\", 10],[\"June\", 5]],  columns=['key', 'value'])\ndisplay(df, font_path=jp_font_path)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"handlerId": "mySimpleWordCloud", "valueFields": "value", "rendererId": "matplotlib", "keyFields": "key"}}}, "outputs": [], "execution_count": null}, {"source": "<a id=\"setupenv\"></a>\n## 2. \u74b0\u5883\u6e96\u5099\n\n\u4ee5\u4e0b\u306e3\u3064\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u74b0\u5883\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3059\u3002\n\n1:  Twitter API\u3092\u4f7f\u7528\u3057\u3066Tweet Data\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\nTwitter API KEY\u306e\u53d6\u5f97\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u3053\u3067\u306f\u305d\u306e\u53d6\u5f97\u65b9\u6cd5\u306f\u8aac\u660e\u3057\u307e\u305b\u3093\u306e\u3067\u3001\u304a\u6301\u3061\u3067\u306a\u3044\u65b9\u306f\u300cTwitter API KEY \u53d6\u5f97\u300d\u7b49\u3067\u691c\u7d22\u3057\u3001\u53d6\u5f97\u304a\u9858\u3044\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u306e4\u3064\u306e\u5024\u304c\u5fc5\u8981\u3067\u3059\u3002\n\n* AccessToken\n* AccessTokenSecret\n* ConsumerKey\n* ConsumerSecret\n\n2:  IBM Cloud Natural Language Understanding \u30b5\u30fc\u30d3\u30b9\u3067Tweet\u3092\u5206\u6790\u3057\u307e\u3059\u3002\nNatural Language Understanding \u30b5\u30fc\u30d3\u30b9\u306e\u4f5c\u6210\u3057APIKEY,URL\u306e\u5024\u304c\u5fc5\u8981\u3067\u3059\u3002\nNatural Language Understanding \u30b5\u30fc\u30d3\u30b9\u304c\u672a\u4f5c\u6210\u306e\u65b9\u306f\u3001[\u3053\u3061\u3089](https://cloud.ibm.com/catalog/services/natural-language-understanding)\u3088\u308a\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n3: \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3084\u4f5c\u6210\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092IBM Cloud Object Strage\u3092\u4f7f\u7528\u3057\u3066\u3066\u8aad\u307f\u8fbc\u307f\u3001\u4fdd\u5b58\u3057\u307e\u3059\u3002\nIBM Cloud Object Strage\u3092\u4f7f\u7528\u3059\u308b\u8a2d\u5b9a\u3092\u4ee5\u4e0b\u3067\u884c\u3044\u307e\u3059\u3002\n\n### 2.1 apikeys.ini\u306e\u4f5c\u6210\n\u6e96\u5099\u3057\u305f\u4e0a\u8a18\u306e\u5024\u3092apikeys.ini\u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u81ea\u5206\u306ePC\u4e0a\u3067\u4f5c\u6210\u3057\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5024\u3092\u8a18\u5165\u3057\u3066\u4fdd\u5b58\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n[\u3000]\u3067\u304b\u3053\u307e\u308c\u305f\u90e8\u5206\u3092\u81ea\u5206\u306eKEY\u306b\u5909\u66f4\u3057\u307e\u3059\u3002[\u3000]\u306f\u4e0d\u8981\u3067\u3059\u306e\u3067\u6b8b\u3055\u306a\u3044\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n```\n[TWITTER]\nTWITTER_AccessToken=[AccessToken\u306e\u5024]\nTWITTER_AccessTokenSecret=[AccessTokenSecret\u306e\u5024]\nTWITTER_ConsumerKey=[ConsumerKey\u306e\u5024]\nTWITTER_ConsumerSecret=[ConsumerSecre\u306e\u5024]\n[IBM]\nNLU_APIKEY=[Natural Language Understanding\u30b5\u30fc\u30d3\u30b9\u306eAPI\u306e\u5024]\nNLU_URL=[Natural Language Understanding\u30b5\u30fc\u30d3\u30b9\u306eURL\u306e\u5024]\n```\n\n### 2.2 apikeys.ini\u306e\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\nWatson Studio\u306ejupyter note book\u4e0a\u3001\u53f3\u4e0a\u306e`0101`\u3068\u3044\u3046\u30a2\u30a4\u30b3\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3057\u3001File\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u306e\u753b\u9762\u3092\u51fa\u3057\u307e\u3059\u3002`Drop your file here or browse your files to add a new file` \u3068\u66f8\u3044\u3066\u3042\u308b\u5834\u6240\u306b\u30012.1\u3067\u4f5c\u6210\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u30c9\u30ed\u30c3\u30d7\u3057\u3001Watson Studio\u4e0a\u306eProject\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "<a id='load'></a> \n### 2.3 apikeys.ini\u306e\u8aad\u307f\u8fbc\u307f\n\n\u30001. **\u4e0b\u306e\u30bb\u30eb\u3092\u9078\u629e\u3057\u3066\u3001\u7a7a\u306e\u884c\u306b\u30ab\u30fc\u30bd\u30eb\u3092\u7f6e\u3044\u3066\u304f\u3060\u3055\u3044\u3002** \n\n2. \u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u305fTweeterAPIKey.ini\u30d5\u30a1\u30a4\u30eb\u306e\u4e0b\u306b\u3042\u308b(\u898b\u3048\u306a\u3044\u5834\u5408\u306f\u53f3\u4e0a\u306e10/01\u30a2\u30a4\u30b3\u30f3\u3092\u30af\u30ea\u30c3\u30af) `Insert to code`\u306e\u4e0b\u306b\u3042\u308b`Insert StreamingBody object`\u3092\u30af\u30ea\u30c3\u30af\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n3. \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u30b9\u30c8\u30ea\u30fc\u30e0`streaming_body_2`\u3092\u30bb\u30c3\u30c8\u3059\u308b\u30b3\u30fc\u30c9\u304c\u633f\u5165\u3055\u308c\u307e\u3059\u3002\n\n4.  4\u7b87\u6240\u3042\u308b`streaming_body_2`\u306f\u3000\u5168\u3066`streaming_body_1`\u306b\u5909\u66f4\u3057\u307e\u3059\u3002(\u5f8c\u306e\u30b3\u30fc\u30c9\u3067\u4f7f\u7528\u3059\u308b\u305f\u3081)\n\n<p><span style=\"color: teal\">\n# Your data file was loaded into a botocore.response.StreamingBody object.<br/>\n# Please read the documentation of ibm_boto3 and pandas to learn more about your possibilities to load the data.<br/>\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/<br/>\n# pandas documentation: http://pandas.pydata.org/<br/></span>\n<strong>streaming_body_1</strong> = client_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.get_object(Bucket='wordcloud-donotdelete-pr-wyztdevipqhfkt', Key='apikeys.ini')['Body']</p>\n<p><span style=\"color: teal\">\n # add missing __iter__ method, so pandas accepts body as file-like object</span>\nif not hasattr(<strong>streaming_body_2</strong>, \"__iter__\"): <strong>streaming_body_2</strong>.__iter__ = types.MethodType( __iter__, <strong>streaming_body_2</strong> ) \n</p>\n\n\n## <span style=\"color: red\">\u3053\u306e\u4e0b\u306b\u5165\u529b </span>", "cell_type": "markdown", "metadata": {}}, {"source": "# \u3053\u306e\u884c\u306e\u4e0b\u306b\u30ab\u30fc\u30bd\u30eb\u3092\u7f6e\u3044\u3066\u3001Insert StreamingBody object\u3092\u30af\u30ea\u30c3\u30af\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### 2.4 ConfigParser\u3078\u306e\u8a2d\u5b9a\u60c5\u5831\u306e\u8aad\u307f\u8fbc\u307f", "cell_type": "markdown", "metadata": {}}, {"source": "import configparser\n\ninifile = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())\ninifile.read_string(streaming_body_1.read().decode('utf-8'))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### 2.5 IBM Objerct Strage\u306eCredential\u30bb\u30c3\u30c8\n\u7d50\u679c\u306e\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58\u306b\u4f7f\u7528\u3059\u308b\u305f\u3081\u3001IBM Objerct Strage\u306eCredential\u3092\u30bb\u30c3\u30c8\u3057\u307e\u3059\u3002\n\n\u30001. **\u4e0b\u306e\u30bb\u30eb\u3092\u9078\u629e\u3057\u3066\u3001\u7a7a\u306e\u884c\u306b\u30ab\u30fc\u30bd\u30eb\u3092\u7f6e\u3044\u3066\u304f\u3060\u3055\u3044\u3002** \n\n2. \u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u305fTweeterAPIKey.ini\u30d5\u30a1\u30a4\u30eb\u306e\u4e0b\u306b\u3042\u308b(\u898b\u3048\u306a\u3044\u5834\u5408\u306f\u53f3\u4e0a\u306e10/01\u30a2\u30a4\u30b3\u30f3\u3092\u30af\u30ea\u30c3\u30af) `Insert to code`\u306e\u4e0b\u306b\u3042\u308b`Insert Credentials`\u3092\u30af\u30ea\u30c3\u30af\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n3. \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u30b9\u30c8\u30ea\u30fc\u30e0`credentials_2`\u3092\u30bb\u30c3\u30c8\u3059\u308b\u30b3\u30fc\u30c9\u304c\u633f\u5165\u3055\u308c\u307e\u3059\u3002\n\n4.  4\u7b87\u6240\u3042\u308b`streaming_body_2`\u306f\u3000\u5168\u3066credentials_1`\u306b\u5909\u66f4\u3057\u307e\u3059\u3002(\u5f8c\u306e\u30b3\u30fc\u30c9\u3067\u4f7f\u7528\u3059\u308b\u305f\u3081)\n\n<p><span style=\"color: teal\">\n# @hidden_cell<br/>\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.<br/>\n# You might want to remove those credentials before you share your notebook.<br/>\n</span>\n<strong> credentials_2</strong>  = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-xxxxxxxx-xxxx-xxxx-xxxx-1234567890xx',<br/>\n    'IBM_API_KEY_ID': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx',<br/>\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',<br/>\n    'IBM_AUTH_ENDPOINT': 'https://iam.bluemix.net/oidc/token',<br/>\n    'BUCKET': 'wordcloud-donotdelete-pr-wyztdevipqhfkt',<br/>\n    'FILE': 'apikeys.ini'<br/>\n}</p>\n\n## <span style=\"color: red\">\u3053\u306e\u4e0b\u306b\u5165\u529b </span>", "cell_type": "markdown", "metadata": {}}, {"source": "# \u3053\u306e\u884c\u306e\u4e0b\u306b\u30ab\u30fc\u30bd\u30eb\u3092\u7f6e\u3044\u3066\u3001Insert\u3000Credentials\u3092\u30af\u30ea\u30c3\u30af\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"gettweets\"></a>\n## 3. Tweet\u60c5\u5831\u306e\u53d6\u5f97\u3068\u4fdd\u5b58", "cell_type": "markdown", "metadata": {}}, {"source": "### 2.1 \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a2d\u5b9a\n\u691c\u7d22\u3057\u305f\u3044\u6587\u5b57\u5217\u3001\u53d6\u5f97\u3057\u305f\u3044Tweet\u6570\u3001\u691c\u7d22\u306e\u7e70\u308a\u8fd4\u3057\u56de\u6570\u3092\u30bb\u30c3\u30c8\u3002\n1\u56de\u306e\u691c\u7d22\u3067\u6700\u5927100 \u4ef6\u3057\u304b\u53d6\u5f97\u3067\u304d\u306a\u3044\u306e\u3067\u3001\u305d\u308c\u4ee5\u4e0a\u53d6\u5f97\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u7e70\u308a\u8fd4\u3057\u56de\u6570\u3092\u30bb\u30c3\u30c8\u3059\u308b\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "#\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30bb\u30c3\u30c8\u3059\u308b\n#\u691c\u7d22\u3057\u305f\u3044\u6587\u5b57\u5217\n#\u57fa\u672c\u306f\u6700\u65b01\u9031\u9593\u5206\nsearch_key = \"#BMXUG\"\n\n#1\u56de\u306e\u691c\u7d22\u3067\u53d6\u5f97\u3057\u305f\u3044Tweet\u6570, \u6700\u5927\u306f\uff11\uff10\uff10\nsearch_count=100\n\n#\u691c\u7d22\u306e\u7e70\u308a\u8fd4\u3057\u56de\u6570\nrepeat_count=2\n\n#search_until=\"2019-04-07\" #\u671f\u9593\u3092\u6307\u5b9a\u3057\u305f\u3044\u5834\u5408\u306f\u30b3\u30e1\u30f3\u30c8\u3092\u306f\u305a\u3059", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### 2.2 Tweet\u60c5\u5831\u306e\u53d6\u5f97\nTwitter Search API\u3092\u4f7f\u3063\u3066\u3001Tweet\u60c5\u5831\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "import json\nimport urllib\nimport calendar\nimport time\nfrom requests_oauthlib import OAuth1Session\n\nCK = inifile['TWITTER']['TWITTER_ConsumerKey']\nCS =  inifile['TWITTER']['TWITTER_ConsumerSecret']\nAT =  inifile['TWITTER']['TWITTER_AccessToken']\nATS =  inifile['TWITTER']['TWITTER_AccessTokenSecret']\ntwitter = OAuth1Session(CK, CS, AT, ATS)  \nsearch_endpoint = \"https://api.twitter.com/1.1/search/tweets.json\"\n\n\n\ndef search_tw(tw, params, search_endpoint):\n\n    url = \"https://api.twitter.com/1.1/search/tweets.json\"  # \u53d6\u5f97\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\n    res = tw.get(search_endpoint, params = params)\n\n    if res.status_code == 200:  # \u6b63\u5e38\u901a\u4fe1\u51fa\u6765\u305f\u5834\u5408\n        timelines = json.loads(res.text)  # \u30ec\u30b9\u30dd\u30f3\u30b9\u304b\u3089\u30bf\u30a4\u30e0\u30e9\u30a4\u30f3\u30ea\u30b9\u30c8\u3092\u53d6\u5f97\n        df_tweets = pd.DataFrame.from_dict(timelines.get('statuses'), dtype='object')\n        next_param = timelines.get('search_metadata').get('next_results')\n        if next_param is not None:\n            next_param = urllib.parse.parse_qs(next_param.replace('?', ''))\n        return df_tweets, next_param\n\n    else:  # \u6b63\u5e38\u901a\u4fe1\u51fa\u6765\u306a\u304b\u3063\u305f\u5834\u5408\n        print(\"Failed: %d\" % res.status_code)\n        raise ValueError(\"Failed: %d\" % res.status_code)\n        \ndef YmdHMS(created_at):\n    time_utc = time.strptime(created_at, '%a %b %d %H:%M:%S +0000 %Y')\n    unix_time = calendar.timegm(time_utc)\n    time_local = time.localtime(unix_time)\n    return str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local))\n               \nparam_dict = {} \nparam_dict['q'] = search_key\n#param_dict['until'] = search_until    #\u671f\u9593\u3092\u6307\u5b9a\u3057\u305f\u3044\u5834\u5408\u306f\u30b3\u30e1\u30f3\u30c8\u3092\u306f\u305a\u3059\nparam_dict['result_type'] = 'recent'\nparam_dict['count'] = search_count\nparam_dict['lang'] = 'ja'\n\nnext_params = param_dict\ndf_tweets= pd.DataFrame()\nlast_id = ''\nfor i in range(int(repeat_count)):\n    print('repaet#:{}'.format(i))\n    df, next_params = search_tw(twitter, next_params, search_endpoint)\n    df_tweets = pd.concat([df_tweets, df], ignore_index=True,)\n    if len(df) == 0:\n        break\n    if next_params is None:\n        before_last_id = last_id\n        last_id = df.tail(1)['id'].astype(str).values[0]\n        if before_last_id == last_id:\n            break\n        param_dict['max_id'] = last_id\n        next_params = param_dict\nif len(df_tweets) > 0:\n    df_tweets['create_at_jst'] = df_tweets.apply(lambda x: YmdHMS(x['created_at']) if x.dtype == \"object\" else x, axis=1)\n    df_tweets = df_tweets.sort_values(by=[\"create_at_jst\"], ascending=True)\n    col_list = list(df_tweets.columns.values)\n    del col_list[-1]\n    col_list.insert(0, 'create_at_jst')\n    df_tweets = df_tweets.reindex(columns=col_list)\nelse:\n    print('No Data')\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### 2.3 Tweet\u60c5\u5831\u306e\u53d6\u5f97\n\u7d50\u679c\u3092\u4e00\u65e6\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "#IBM Object Storage\u3078\u306e\u691c\u7d22\u4fdd\u5b58\ntweet_result_filename = 'tweets_resluts.csv'\n\ncos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials_1['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials_1['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials_1['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials_1['ENDPOINT'])\n\n\n# Write a CSV file from the enriched pandas DataFrame.\ndf_tweets.to_csv(tweet_result_filename, index=False)\n\n# Use the above put_file method with credentials to put the file in Object Storage.\ncos.upload_file(tweet_result_filename, Bucket=credentials_1['BUCKET'],Key=tweet_result_filename)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"donulu\"></a>\n## 4. Tweet\u304b\u3089Natural Language Understanding\u3092\u4f7f\u7528\u3057\u3066Keyword\u62bd\u51fa\n\n### 4.1 \u524d\u51e6\u7406\u5f8cNLU\u547c\u3073\u51fa\u3057\u3068\u5408\u8a08\u51e6\u7406", "cell_type": "markdown", "metadata": {}}, {"source": "from ibm_watson import NaturalLanguageUnderstandingV1\nfrom ibm_watson.natural_language_understanding_v1 import Features, KeywordsOptions\n\n\ndf_tweets['refineText']=df_tweets['text']\n\n# \u6539\u884c\u524a\u9664\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('\\n', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].strip(), axis=1)\n\n# RT\u30de\u30fc\u30af\u524a\u9664\ndf_tweets['refineText'] = df_tweets['refineText'].replace(r'^RT.*?:', '', regex=True)\n\n# hasshutag\u8a18\u53f7(#)\u524a\u9664\ndf_tweets['refineText'] = df_tweets['refineText'].replace(r'#(\\w+)', '', regex=True)\n\n# Strip links from Text column\ndf_tweets['refineText'] = df_tweets['refineText'].apply(lambda x: x.split('http')[0])\n\n# \u30ab\u30c3\u30b3\u524a\u9664\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('(', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace(')', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('\u3010', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('\u3011', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('[', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace(']', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('\u300c', ' '), axis=1)\ndf_tweets['refineText'] = df_tweets.apply(lambda x: x['refineText'].replace('\u300d', ' '), axis=1)\n\n\nnlu = NaturalLanguageUnderstandingV1(version='2018-11-16', url=inifile['IBM']['NLU_URL'], iam_apikey=inifile['IBM']['NLU_APIKEY'])\n\nfeatures = Features(keywords=KeywordsOptions())\nkeywords = []\ndf_pixiedust = pd.DataFrame(columns=['Key', 'Value'])\n\n\nfor text, i in zip(df_tweets['refineText'], df_tweets.index):\n    if not text:\n        keywords.append(' ')\n        continue\n\n    enriched_json = nlu.analyze(text=text, features=features, language='ja')\n\n    # Iterate and get KEYWORDS with a confidence of over 70%\n    if 'keywords' in enriched_json.result:\n        tmpkw = []\n        for kw in enriched_json.result[\"keywords\"]:\n            if (float(kw[\"relevance\"]) >= 0.7):\n                tmpkw.append(kw[\"text\"])\n                df_pixiedust = df_pixiedust.append({'Key': kw[\"text\"], 'Value': 1}, ignore_index=True)\n        # Convert multiple keywords in a list to a string and append the string\n        keywords.append(', '.join(tmpkw))\n    else:\n        keywords.append(\"\")\n    print('{}:keyword: {}'.format(i, tmpkw))\n\ndf_tweets['Keywords'] = keywords\n\ndf_pixiedust = df_pixiedust.groupby('Key').count()\ndf_pixiedust = df_pixiedust.sort_values(by=[\"Value\"], ascending=False)\ndf_pixiedust = df_pixiedust.reset_index()\n\n# Write a CSV file from the enriched pandas DataFrame.\ndf_tweets.to_csv(tweet_result_filename, index=False)\n\n# Use the above put_file method with credentials to put the file in Object Storage.\ncos.upload_file(tweet_result_filename, Bucket=credentials_1['BUCKET'],Key=tweet_result_filename)", "cell_type": "code", "metadata": {"scrolled": true}, "outputs": [], "execution_count": null}, {"source": "### 4.2\u3000\u62bd\u51fa\u30c7\u30fc\u30bf\u78ba\u8a8d", "cell_type": "markdown", "metadata": {}}, {"source": "df_pixiedust", "cell_type": "code", "metadata": {"scrolled": true}, "outputs": [], "execution_count": null}, {"source": "### 4.3 WordCloud\u3067\u8868\u793a\u3057\u3066\u307f\u307e\u3057\u3087\u3046!", "cell_type": "markdown", "metadata": {}}, {"source": "display(df_pixiedust, font_path = '/home/dsxuser/work/ipaexg00301/ipaexg.ttf')\n", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"tableFields": "Key,Value", "no_margin": "true", "orientation": "horizontal", "chartsize": "77", "mpld3": "false", "aggregation": "SUM", "filter": "{\"value\": \"5\", \"regex\": \"False\", \"constraint\": \"greater_than\", \"case_matter\": \"False\", \"field\": \"Value\"}", "rowCount": "10", "handlerId": "mySimpleWordCloud", "valueFields": "Value", "rendererId": "matplotlib", "sortby": "Values DESC", "ylabel": "true", "keyFields": "Key", "legend": "false"}}}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "celltoolbar": "Edit Metadata"}, "nbformat": 4}